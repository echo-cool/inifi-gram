{
  "builder_name": "snli",
  "citation": "@inproceedings{snli:emnlp2015,\n\tAuthor = {Bowman, Samuel R. and Angeli, Gabor and Potts, Christopher, and Manning, Christopher D.},\n\tBooktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)},\n\tPublisher = {Association for Computational Linguistics},\n\tTitle = {A large annotated corpus for learning natural language inference},\n\tYear = {2015}\n}\n",
  "config_name": "plain_text",
  "dataset_name": "snli",
  "dataset_size": 68691466,
  "description": "The SNLI corpus (version 1.0) is a collection of 570k human-written English\nsentence pairs manually labeled for balanced classification with the labels\nentailment, contradiction, and neutral, supporting the task of natural language\ninference (NLI), also known as recognizing textual entailment (RTE).\n",
  "download_checksums": {},
  "download_size": 94550081,
  "features": {
    "premise": {
      "dtype": "string",
      "_type": "Value"
    },
    "hypothesis": {
      "dtype": "string",
      "_type": "Value"
    },
    "label": {
      "names": [
        "entailment",
        "neutral",
        "contradiction"
      ],
      "_type": "ClassLabel"
    },
    "id": {
      "dtype": "int64",
      "_type": "Value"
    }
  },
  "homepage": "https://nlp.stanford.edu/projects/snli/",
  "license": "",
  "size_in_bytes": 163241547,
  "splits": {
    "test": {
      "name": "test",
      "num_bytes": 1263912,
      "num_examples": 10000,
      "dataset_name": "snli"
    },
    "train": {
      "name": "train",
      "num_bytes": 66159510,
      "num_examples": 550152,
      "dataset_name": "snli"
    },
    "validation": {
      "name": "validation",
      "num_bytes": 1268044,
      "num_examples": 10000,
      "dataset_name": "snli"
    }
  },
  "version": {
    "version_str": "1.0.0",
    "description": "New split API (https://tensorflow.org/datasets/splits)",
    "major": 1,
    "minor": 0,
    "patch": 0
  }
}